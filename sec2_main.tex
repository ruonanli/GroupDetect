\section{Matching and Localizing Social Interactions}


Consider an input video consisting of $T$ temporal units, with each unit being a frame or several consecutive frames. By applying domain-appropriate detection and tracking, assume we obtain $M$ space-time tracks of bounding boxes enclosing $M$ faces or bodies. Note that these $M$ tracks may include non-participants and false-alarm bounding boxes resulted from an imperfect detector. The $M$ targets are to be compared with the social interaction exemplars pre-stored in a database. Such an exemplar consists of $S$ temporal units and $N$ targets that are correctly detected and tracked and all participating in an coherent social interaction. As the input may include non-participants and false-positive tracks, it contains the same or more targets than the exemplar, \textit{i.e.}, $N\leq M$.

The first question is how to represent the two sets of size $M\times T$ and $N\times S$. A social interaction is not only a collection of individual activities, but is more crucially characterized by the mutual contexts between individuals. Our representation for the input tracks is consequently made up of two parts. The first part is a collection of $M\times T$ $d_{I}$-dimensional descriptors $\{\mathbf{f}_{m,t}\}_{m=1,2,\cdots,M, t=1,2,\cdots,T}$, where $\mathbf{f}_{m,t}$ encodes the individual activity of the $m$th target at time $t$. The other part is a collection of $M\times (M-1)\times T$ $d_{P}$-dimensional pairwise contextual descriptors $\{\mathbf{g}_{m,m',t}\}_{m,m'=1,2,\cdots,M, m\neq m', t=1,2,\cdots,T}$, where $\mathbf{g}_{m,m',t}$ encodes dynamic visual properties of target $m$ that are exhibited relative to those of target $m'$ at time $t$. Loosely speaking, $\mathbf{g}_{m,m',t}$ describes the `influence' that target $m'$ exhibits over target $m$ at time $t$, with the possibility that $\mathbf{g}_{m,m',t}\ne\mathbf{g}_{m',m,t}$. The form of descriptors $\mathbf{f}_{m,t}$ and $\mathbf{g}_{m,m',t}$ will be application dependent, and will be further discussed in experiment section. For each exemplar, we have two similar descriptor collections $\{\mathbf{f}^{D}_{n,s}\}_{n=1,2,\cdots,N, s=1, 2,\cdots, S}$ and $\{\mathbf{g}^{D}_{n,n',s}\}_{n,n'=1,2,\cdots,N, n\neq n', s=1, 2,\cdots, S}$. We denote the descriptor ensemble for the input at time $t$ to be $\mathcal{Q}_{t}\triangleq\{\mathbf{f}_{m,t},\mathbf{g}_{m,m',t}\}$, and that for the exemplar at time $s$ as $\mathcal{D}_{s}\triangleq\{\mathbf{f}^{D}_{n,s},\mathbf{g}^{D}_{n,n',s}\} $. As a result, the input can be represented as $\mathcal{Q}\triangleq\{\mathcal{Q}_{t}\}_{1\leq t\leq T}$ and the exemplar $\mathcal{D}\triangleq\{\mathcal{D}_{s}\}_{1\leq s\leq S}$.


Given the input and the exemplar, our primary tasks are to identify from the $M$ targets in the input $N$ targets that demonstrate the most similar socially interactive pattern as the $N$ individuals in the exemplar, as well as to temporally localize the extent of the interaction within the interval $[1, T]$. To formally describe the former task, consider the fact that if one of the $M$ targets is regarded as a participant in an interaction as exemplified by the exemplar $\mathcal{D}$, its behavior should properly match to the behavior of one of the $N$ individuals in the exemplar $\mathcal{D}$. Therefore, we use a $N\times M$ binary matrix $W=[w_{nm}]\in\{0,1\}^{N\times M}$ to formally represent the participant identification, where $w_{nm}=1$ means that the $n$th exemplar individual is matched to the $m$th input target and $w_{nm}=0$ means unmatched targets. For unambiguous matching, we expect each individual in the exemplar to find its unique partner target in the input. This implies that $\sum_{m}w_{nm}=1, \forall n$ and $\sum_{n}w_{nm}\leq 1, \forall m$, \textit{i.e.}, $W\mathbf{1}=\mathbf{1}$ and $\mathbf{1}^{T}W\leq\mathbf{1}^{T}$\footnote{Note that false-alarm tracks are already accounted for in the partial matching, and if we set the values of the descriptors of an out-of-scene target to be sufficiently large (or small) numbers, this target will not be matched with any target in the exemplar.}. Denote $\mathcal{W}\triangleq\{W\in\{0,1\}^{N\times M}| W\mathbf{1}=\mathbf{1}, \mathbf{1}^{T}W\leq\mathbf{1}^{T}\}$, and our former task is essentially to find $W^{*}\in\mathcal{W}$, which encodes the best matching between the input $\mathcal{Q}$ and the exemplar $\mathcal{D}$. To formally describe the latter task is straightforward: We simply look for the starting time $T_{s}$ and ending time $T_{e}$, $1\le T_{s}<T_{e}\le T$, such that the interactive pattern of input $\mathcal{Q}$ during $[T_{s}, T_{e}]$ demonstrate the best similarity with the exemplar $\mathcal{D}$.

Our computational framework has three steps as illustrated in Figure \ref{diagram}. The first step is to evaluate $T\times S$ dis-similarity scores $D(\mathcal{Q}_{t}, \mathcal{D}_{s})$ together with their 'instantaneous optimal matching' $W^{t,s}$ between each time unit  $1\le t\le T$ and each time unit  $1\le s\le S$ (Section \ref{agg}). This is followed by a dual-accumulator Hough voting procedure to find the best matching $W^{*}$ (Section \ref{vote}). Finally, an efficient branch-and-bound search estimates the temporal extent $[T_{s}, T_{e}]$ (Section \ref{BB}).  